{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Do all necessary preprocessing, calling prepro.py\n",
    "import utils\n",
    "from utils import *\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, X_test_original, y = load_data() \n",
    "y = y.ravel()\n",
    "scores = np.array([])\n",
    "xtrain = X  # For andreas cross validation\n",
    "ytrain = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN1 model (edited by Nico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN1():\n",
    "    def __init__(self):\n",
    "        self.mlp = KerasClassifier(build_fn=self.create_model, \n",
    "                                   epochs=15, batch_size=35, \n",
    "                                   verbose=1)\n",
    "        return\n",
    "    \n",
    "    def score(self, X_, y_):\n",
    "        pred = self.predict(X_)\n",
    "        if y_.shape[1] < 2:\n",
    "            y_normal = y_\n",
    "        else:\n",
    "            y_normal = np.argmax(y_, axis=1)\n",
    "        BMAC = balanced_accuracy_score(y_normal, pred)\n",
    "        return BMAC\n",
    "    \n",
    "    def fit(self, X_, y_):\n",
    "        # One hot encode data\n",
    "        y_enc = np.zeros((y_.shape[0], 3))\n",
    "        y_enc[np.arange(y_.shape[0]), y_] = 1\n",
    "        \n",
    "        xscaled = preprocessing.StandardScaler().fit_transform(X_)\n",
    "        cw = sklearn.utils.class_weight.compute_class_weight('balanced', np.unique(y_), y_)\n",
    "        class_weight = {0: cw[0], 1: cw[1], 2: cw[2]}\n",
    "        self.mlp.fit(xscaled, y_enc, class_weight=class_weight)\n",
    "        return\n",
    "    \n",
    "    def predict(self, X_):\n",
    "        return self.mlp.predict(preprocessing.StandardScaler().fit_transform(X_))\n",
    "    \n",
    "    def create_model(self):\n",
    "        # create model\n",
    "        neurons = 1000\n",
    "        dropout_rate = 0.5\n",
    "        weight_constraint = 4\n",
    "        model = Sequential()\n",
    "        model.add(Dense(neurons, input_dim=1000, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(neurons, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model.add(Dropout(dropout_rate*0.4))\n",
    "        model.add(Dense(int(neurons/2), activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model.add(Dropout(dropout_rate*0.2))\n",
    "        model.add(Dense(3, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def predict_proba(self, X_):\n",
    "        return self.mlp.predict_proba(preprocessing.StandardScaler().fit_transform(X_))\n",
    "\n",
    "# nn = NN1()\n",
    "# nn.fit(X[1:10], y[1:10])\n",
    "# ypredy = nn.predict(X[1:10])\n",
    "# probbb = nn.predict_proba(X[1:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble dei modelliiiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ensemble voting classifier fn:\n",
    "\n",
    "def ensemby(y1_prob, y2_prob, voting='soft'):\n",
    "    # Return the argmax of the sum of the probabilities\n",
    "    return np.argmax(y1_prob + y2_prob, axis=1)\n",
    "\n",
    "# Prepare the SVM\n",
    "andreas_svm = svm.SVC(C=0.5, class_weight='balanced', degree=1, gamma='auto', kernel='rbf', probability=True)\n",
    "steps = [(\"scaler\", preprocessing.StandardScaler()), (\"classifier\", andreas_svm)]\n",
    "svm_pipeline = Pipeline(steps = steps)\n",
    "\n",
    "# Prepare the NN1\n",
    "nn = NN1()\n",
    "\n",
    "# Models to fit\n",
    "print(\"Fitting SVM...\")\n",
    "svm_pipeline.fit(x_train, y_train.ravel())\n",
    "print(\"Fitting NN...\")\n",
    "nn.fit(x_train, y_train.ravel())\n",
    "\n",
    "# Predict and join the predictions\n",
    "svm_pred = svm_pipeline.predict(x_test)\n",
    "nn_pred = nn.predict(x_test)\n",
    "svm_prob = svm_pipeline.predict_proba(x_test)\n",
    "nn_prob = nn.predict_proba(x_test)\n",
    "ensemble_pred = ensemby(svm_prob, nn_prob)\n",
    "\n",
    "# Record scores\n",
    "BMAC_ensemble = balanced_accuracy_score(y_test, ensemble_pred)\n",
    "BMAC_svm = balanced_accuracy_score(y_test, svm_pred)\n",
    "BMAC_nn = balanced_accuracy_score(y_test, nn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(0, len(svm_pred)), svm_pred)\n",
    "plt.scatter(range(0, len(svm_pred)), nn_pred)\n",
    "plt.scatter(range(0, len(svm_pred)), ensemble_pred)\n",
    "\n",
    "# Find where ensemble pred is diff from theirs:\n",
    "# Case 1: When both predictions are same, does the ensemble ever get it wrong?\n",
    "((svm_pred == nn_pred) & (svm_pred != ensemble_pred)).nonzero()[0]\n",
    "# ^ This is nonempty, so the answer is yes. \n",
    "\n",
    "# Check that the probability thing is acting correctly for svm\n",
    "idx = (np.argmax(svm_prob, axis=1) != svm_pred).nonzero()[0]\n",
    "# Yes, there are times where it guesses wrong based on probability! so svm_pred is not equal to svm_prob?\n",
    "print(np.argmax((svm_prob[idx][0:5]), axis=1))\n",
    "print(svm_prob[idx][0:5])\n",
    "print(svm_pred[idx][0:5])\n",
    "\n",
    "# Try to remove standardization:\n",
    "svm_prob2 = andreas_svm.predict_proba(x_test)\n",
    "svm_pred2 = andreas_svm.predict(x_test)\n",
    "idx = (np.argmax(svm_prob2, axis=1) != svm_pred).nonzero()[0]\n",
    "# Yes, there are times where it guesses wrong based on probability! so svm_pred is not equal to svm_prob?\n",
    "print(np.argmax((svm_prob2[idx][0:5]), axis=1))\n",
    "print(svm_prob2[idx][0:5])\n",
    "print(svm_pred[idx][0:5])\n",
    "\n",
    "\n",
    "# Check that the probability thing is acting correctly for nn\n",
    "# idx = (np.argmax(nn_prob, axis=1) != nn_pred).nonzero()[0]\n",
    "# print(\"Idx nn:\", idx)\n",
    "# The above is empty, so nn is working fine\n",
    "\n",
    "\n",
    "# Case 2: When both predictions are different, does the ensemble always \n",
    "# ((svm_pred != nn_pred) & (ensemble_pred != nn_pred)).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVM...\n",
      "Fitting SVM...\n",
      "idx 1: [ 0  3  4  5  8  9 15 19 22 25 26 29 31 34 37 39 43 44 46 49 54 56 57 58\n",
      " 65 67 68 69 73 77 82 84 90 92 94]\n",
      "idx 2: [ 0  3  4  5  8  9 13 15 19 22 25 26 29 31 33 34 37 39 40 41 43 44 46 47\n",
      " 49 52 53 54 55 56 57 58 65 67 68 69 70 73 75 77 80 82 84 85 90 92 94]\n"
     ]
    }
   ],
   "source": [
    "# Refit andreas svm and test that prob ting eh\n",
    "\n",
    "x_test2 = X[201:300]\n",
    "x_train2 = X[1:100]\n",
    "y_train2 = y[1:100]\n",
    "\n",
    "# Prepare the SVM\n",
    "andreas_svm = svm.SVC(C=0.5, class_weight='balanced', degree=1, gamma='auto', kernel='rbf', probability=True)\n",
    "steps = [(\"scaler\", preprocessing.StandardScaler()), (\"classifier\", andreas_svm)]\n",
    "svm_pipeline = Pipeline(steps = steps)\n",
    "\n",
    "print(\"Fitting SVM...\")\n",
    "svm_pipeline.fit(x_train2, y_train2.ravel())\n",
    "\n",
    "# Predict and join the predictions\n",
    "svm_pred = svm_pipeline.predict(x_test2)\n",
    "svm_prob = svm_pipeline.predict_proba(x_test2)\n",
    "\n",
    "# VERSUS:\n",
    "\n",
    "# Prepare the SVM\n",
    "svm2 = svm.SVC(C=0.5, class_weight='balanced', degree=1, gamma='auto', kernel='rbf', probability=True)\n",
    "\n",
    "print(\"Fitting SVM...\")\n",
    "svm2.fit(x_train2, y_train2.ravel())\n",
    "\n",
    "# Predict and join the predictions\n",
    "svm2_pred = svm2.predict(x_test2)\n",
    "svm2_prob = svm2.predict_proba(x_test2)\n",
    "\n",
    "# Test whether pipeline pred is consistent with prob:\n",
    "idx = (np.argmax(svm_prob, axis=1) != svm_pred).nonzero()[0]\n",
    "print(\"idx 1:\", idx)\n",
    "# Answer: no, cus idx non empty\n",
    "\n",
    "# Test whether isolated pred is consistent with prob:\n",
    "idx = (np.argmax(svm2_prob, axis=1) != svm2_pred).nonzero()[0]\n",
    "print(\"idx 2:\", idx)\n",
    "# Answer: no, cus idx non empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acgtual ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big cross val for loop\n",
    "\n",
    "# Try a nn Estimator with SMOTE\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "\n",
    "BMAC_means = np.array([])\n",
    "BMAC_stds = np.array([])\n",
    "BMAC_scores = np.array([])\n",
    "svm_scores = np.array([])\n",
    "nn_scores = np.array([])\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "\n",
    "    # Prepare the data\n",
    "    x_train = xtrain[train_index]\n",
    "    x_test = xtrain[test_index]\n",
    "    y_train = ytrain[train_index]\n",
    "    y_test = ytrain[test_index]\n",
    "\n",
    "    # Prepare the SVM\n",
    "    andreas_svm = svm.SVC(C=0.5, class_weight='balanced', degree=1, gamma='auto', kernel='rbf', probability=True)\n",
    "    steps = [(\"scaler\", preprocessing.StandardScaler()), (\"classifier\", andreas_svm)]\n",
    "    svm_pipeline = Pipeline(steps = steps)\n",
    "    \n",
    "    # Prepare the NN1\n",
    "    nn = NN1()\n",
    "    \n",
    "    # Models to fit\n",
    "    print(\"Fitting SVM...\")\n",
    "    svm_pipeline.fit(x_train, y_train.ravel())\n",
    "    print(\"Fitting NN...\")\n",
    "    nn.fit(x_train, y_train.ravel())\n",
    "    \n",
    "    # Predict and join the predictions\n",
    "    svm_pred = svm_pipeline.predict(x_test)\n",
    "    nn_pred = nn.predict(x_test)\n",
    "    svm_prob = svm_pipeline.predict_proba(x_test)\n",
    "    nn_prob = nn.predict_proba(x_test)\n",
    "    ensemble_pred = ensemby(svm_prob, nn_prob)\n",
    "    \n",
    "    # Record scores\n",
    "    BMAC_ensemble = balanced_accuracy_score(y_test, ensemble_pred)\n",
    "    BMAC_svm = balanced_accuracy_score(y_test, svm_pred)\n",
    "    BMAC_nn = balanced_accuracy_score(y_test, nn_pred)\n",
    "    print(\"BMAC Ensemble Scores: \", BMAC_ensemble)\n",
    "    print(\"BMAC SVM Scores: \", BMAC_svm)\n",
    "    print(\"BMAC NN Scores: \", BMAC_nn)\n",
    "    BMAC_scores = np.append(BMAC_scores, BMAC_ensemble)\n",
    "    svm_scores = np.append(svm_scores, BMAC_svm)\n",
    "    nn_scores = np.append(nn_scores, BMAC_nn)\n",
    "    \n",
    "BMAC_means = np.append(BMAC_means, np.mean(BMAC_scores))\n",
    "BMAC_stds = np.append(BMAC_stds, np.std(BMAC_scores))\n",
    "\n",
    "print(\"Scores:\", BMAC_scores)\n",
    "print(\"SVM Scores:\", svm_scores)\n",
    "print(\"NN Scores:\", nn_scores)\n",
    "print(\"Mean Scores:\", BMAC_means)\n",
    "print(\"Std Scores:\", BMAC_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
